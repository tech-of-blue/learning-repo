{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22 pydantic==2.10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGSMITH_TRACING_V2: None\n",
      "LANGSMITH_ENDPOINT: https://api.smith.langchain.com\n",
      "LANGSMITH_PROJECT: agent-book\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env ファイルを読み込む\n",
    "path_env=\"C:\\\\Users\\\\ktgu1\\\\.env\"\n",
    "load_dotenv(path_env)\n",
    "\n",
    "# 環境変数を取得\n",
    "langsmith_tracing_v2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langsmith_endpoint = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "langsmith_project = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "# Langsmithがただしく読み込めているか確認。なぜかtracingがNoneだができてる\n",
    "print(f\"LANGSMITH_TRACING_V2: {langsmith_tracing_v2}\")\n",
    "print(f\"LANGSMITH_ENDPOINT: {langsmith_endpoint}\")\n",
    "print(f\"LANGSMITH_PROJECT: {langsmith_project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = {\n",
    "    \"1\": {\n",
    "        \"name\": \"一般知識エキスパート\",\n",
    "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
    "        \"details\": \"幅広い分野の一般的な質問に対して、正確で分かりやすい回答を提供してください。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"生成AI製品エキスパート\",\n",
    "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
    "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"カウンセラー\",\n",
    "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
    "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description=\"ユーザーからの質問\")\n",
    "    current_role: str = Field(\n",
    "        default=\"\", description=\"選定された回答ロール\"\n",
    "    )\n",
    "    messages: Annotated[list[str], operator.add] = Field(\n",
    "        default=[], description=\"回答履歴\"\n",
    "    )\n",
    "    current_judge: bool = Field(\n",
    "        default=False, description=\"品質チェックの結果\"\n",
    "    )\n",
    "    judgement_reason: str = Field(\n",
    "        default=\"\", description=\"品質チェックの判定理由\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "# 後からmax_tokensの値を変更できるように、変更可能なフィールドを宣言\n",
    "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
    "\n",
    "選択肢:\n",
    "{role_options}\n",
    "\n",
    "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
    "\n",
    "質問: {query}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    # 選択肢の番号のみを返すことを期待したいため、max_tokensの値を1に変更\n",
    "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
    "\n",
    "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
    "    return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
    "\n",
    "役割の詳細:\n",
    "{role_details}\n",
    "\n",
    "質問: {query}\n",
    "\n",
    "回答:\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    judge: bool = Field(default=False, description=\"判定結果\")\n",
    "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
    "また、その判断理由も説明してください。\n",
    "\n",
    "ユーザーからの質問: {query}\n",
    "回答: {answer}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(Judgement)\n",
    "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return {\n",
    "        \"current_judge\": result.judge,\n",
    "        \"judgement_reason\": result.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionノードから処理を開始\n",
    "workflow.set_entry_point(\"selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionノードからansweringノードへ\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "# answeringノードからcheckノードへ\n",
    "workflow.add_edge(\"answering\", \"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# checkノードから次のノードへの遷移に条件付きエッジを定義\n",
    "# state.current_judgeの値がTrueならENDノードへ、Falseならselectionノードへ\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda state: state.current_judge,\n",
    "    {True: END, False: \"selection\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = compiled.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '生成AIについて教えてください',\n",
       " 'current_role': '生成AI製品エキスパート',\n",
       " 'messages': ['生成AI製品エキスパートとしてお答えします。\\n\\n生成AI（生成的人工知能）は、データから新しいコンテンツを生成する能力を持つAI技術の一分野です。これには、テキスト、画像、音声、音楽など、さまざまな形式のコンテンツが含まれます。生成AIの代表的な技術には、以下のようなものがあります。\\n\\n1. **GPT（Generative Pre-trained Transformer）**: これは、自然言語処理に特化したモデルで、テキストの生成や翻訳、要約などに利用されます。OpenAIのGPTシリーズが有名です。\\n\\n2. **GAN（Generative Adversarial Networks）**: これは、2つのニューラルネットワークが競い合うことで、よりリアルなデータを生成する技術です。主に画像生成に利用され、フェイク画像の作成や画像のスタイル変換などに使われます。\\n\\n3. **VAE（Variational Autoencoders）**: これは、データの潜在的な特徴を学習し、新しいデータを生成するためのモデルです。主に画像や音声の生成に利用されます。\\n\\n生成AIは、クリエイティブなコンテンツの制作、自動化されたカスタマーサービス、医療診断の支援、教育コンテンツのパーソナライズなど、さまざまな分野で応用されています。しかし、倫理的な問題やデータのバイアス、プライバシーの懸念などもあり、これらの課題に対する慎重な対応が求められています。\\n\\n生成AIは急速に進化しており、今後も多くの分野でその可能性が広がっていくと考えられています。'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': '回答は生成AIについての基本的な情報を網羅しており、具体例を挙げて技術の説明を行っています。また、生成AIの応用分野や倫理的な課題についても触れており、全体としてバランスの取れた内容です。'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいコンテンツを生成することができます。\n",
      "\n",
      "代表的な生成AIの技術には、以下のようなものがあります。\n",
      "\n",
      "1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPTは、与えられたプロンプトに基づいて、自然で流暢な文章を生成することができます。\n",
      "\n",
      "2. **DALL-E**: 画像生成に特化したモデルで、テキストの説明に基づいて新しい画像を生成します。これにより、ユーザーは想像力を駆使して、ユニークなビジュアルコンテンツを作成することができます。\n",
      "\n",
      "3. **VQ-VAE（Vector Quantized Variational Autoencoder）**: 音声や画像の生成に利用される技術で、データを圧縮し、再構築することで新しいコンテンツを生成します。\n",
      "\n",
      "生成AIは、クリエイティブな分野だけでなく、ビジネス、教育、医療など多岐にわたる分野で応用されています。例えば、カスタマーサポートの自動化、教育コンテンツのパーソナライズ、医療データの解析などに利用されています。\n",
      "\n",
      "この技術は急速に進化しており、今後も新しい応用が期待されています。ただし、生成AIの利用にあたっては、倫理的な配慮やデータのプライバシー保護が重要な課題となっています。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AI（生成的人工知能）は、データから新しいコンテンツを生成する能力を持つAI技術の一分野です。これには、テキスト、画像、音声、音楽など、さまざまな形式のコンテンツが含まれます。生成AIの代表的な技術には、以下のようなものがあります。\n",
      "\n",
      "1. **GPT（Generative Pre-trained Transformer）**: これは、自然言語処理に特化したモデルで、テキストの生成や翻訳、要約などに利用されます。OpenAIのGPTシリーズが有名です。\n",
      "\n",
      "2. **GAN（Generative Adversarial Networks）**: これは、2つのニューラルネットワークが競い合うことで、よりリアルなデータを生成する技術です。主に画像生成に利用され、フェイク画像の作成や画像のスタイル変換などに使われます。\n",
      "\n",
      "3. **VAE（Variational Autoencoders）**: これは、データの潜在的な特徴を学習し、新しいデータを生成するためのモデルです。主に画像や音声の生成に利用されます。\n",
      "\n",
      "生成AIは、クリエイティブなコンテンツの制作、自動化されたカスタマーサービス、医療診断の支援、教育コンテンツのパーソナライズなど、さまざまな分野で応用されています。しかし、倫理的な問題やデータのバイアス、プライバシーの懸念などもあり、これらの課題に対する慎重な対応が求められています。\n",
      "\n",
      "生成AIは急速に進化しており、今後も多くの分野でその可能性が広がっていくと考えられています。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいコンテンツを生成することができます。\n",
      "\n",
      "代表的な生成AIの技術には、以下のようなものがあります。\n",
      "\n",
      "1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPTは、与えられたプロンプトに基づいて、自然で流暢な文章を生成することができます。\n",
      "\n",
      "2. **DALL-E**: 画像生成に特化したモデルで、テキストの説明に基づいて新しい画像を生成します。これにより、ユーザーは想像力を駆使して、ユニークなビジュアルコンテンツを作成することができます。\n",
      "\n",
      "3. **VQ-VAE（Vector Quantized Variational Autoencoder）**: 音声や画像の生成に利用される技術で、データを圧縮し、再構築することで新しいコンテンツを生成します。\n",
      "\n",
      "生成AIは、クリエイティブな分野だけでなく、ビジネス、教育、医療など多岐にわたる分野で応用されています。例えば、カスタマーサポートの自動化、教育コンテンツのパーソナライズ、医療データの解析などに利用されています。\n",
      "\n",
      "この技術は急速に進化しており、今後も新しい応用が期待されています。ただし、生成AIの利用にあたっては、倫理的な配慮やデータのプライバシー保護が重要な課題となっています。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいコンテンツを生成することができます。\n",
      "\n",
      "代表的な生成AIの技術には、以下のようなものがあります。\n",
      "\n",
      "1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPTは、与えられたプロンプトに基づいて、自然で流暢な文章を生成することができます。\n",
      "\n",
      "2. **DALL-E**: 画像生成に特化したモデルで、テキストの説明に基づいて新しい画像を生成します。これにより、ユーザーは想像力を駆使して、ユニークなビジュアルコンテンツを作成することができます。\n",
      "\n",
      "3. **VQ-VAE（Vector Quantized Variational Autoencoder）**: 音声や画像の生成に利用される技術で、データを圧縮し、再構築することで新しいコンテンツを生成します。\n",
      "\n",
      "生成AIは、クリエイティブな分野だけでなく、ビジネス、教育、医療など多岐にわたる分野で応用されています。例えば、カスタマーサポートの自動化、教育コンテンツのパーソナライズ、医療データの解析などに利用されています。\n",
      "\n",
      "この技術は急速に進化しており、今後も新しい応用が期待されています。ただし、生成AIの利用にあたっては、倫理的な配慮やデータのプライバシー保護が重要な課題となっています。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['生成AI製品エキスパートとしてお答えします。\\n\\n生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいコンテンツを生成することができます。\\n\\n代表的な生成AIの技術には、以下のようなものがあります。\\n\\n1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPTは、与えられたプロンプトに基づいて、自然で流暢な文章を生成することができます。\\n\\n2. **DALL-E**: 画像生成に特化したモデルで、テキストの説明に基づいて新しい画像を生成します。これにより、ユーザーは想像力を駆使して、ユニークなビジュアルコンテンツを作成することができます。\\n\\n3. **VQ-VAE（Vector Quantized Variational Autoencoder）**: 音声や画像の生成に利用される技術で、データを圧縮し、再構築することで新しいコンテンツを生成します。\\n\\n生成AIは、クリエイティブな分野だけでなく、ビジネス、教育、医療など多岐にわたる分野で応用されています。例えば、カスタマーサポートの自動化、教育コンテンツのパーソナライズ、医療データの解析などに利用されています。\\n\\nこの技術は急速に進化しており、今後も新しい応用が期待されています。ただし、生成AIの利用にあたっては、倫理的な配慮やデータのプライバシー保護が重要な課題となっています。']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_start callback: ValidationError(model='Run', errors=[{'loc': ('__root__',), 'msg': \"argument of type 'NoneType' is not iterable\", 'type': 'type_error'}])\n",
      "Error in LangChainTracer.on_chain_end callback: TracerException('No indexed run ID 57265f1d-3086-47c4-a56b-620f749e6301.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '生成AIについて教えてください',\n",
       " 'current_role': '生成AI製品エキスパート',\n",
       " 'messages': ['生成AI製品エキスパートとしてお答えします。\\n\\n生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいコンテンツを生成することができます。\\n\\n代表的な生成AIの技術には、以下のようなものがあります。\\n\\n1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPTは、与えられたプロンプトに基づいて、自然で流暢な文章を生成することができます。\\n\\n2. **DALL-E**: 画像生成に特化したモデルで、テキストの説明に基づいて新しい画像を生成します。これにより、ユーザーは想像力を駆使して、ユニークなビジュアルコンテンツを作成することができます。\\n\\n3. **VQ-VAE（Vector Quantized Variational Autoencoder）**: 音声や画像の生成に利用される技術で、データを圧縮し、再構築することで新しいコンテンツを生成します。\\n\\n生成AIは、クリエイティブな分野だけでなく、ビジネス、教育、医療など多岐にわたる分野で応用されています。例えば、カスタマーサポートの自動化、教育コンテンツのパーソナライズ、医療データの解析などに利用されています。\\n\\nこの技術は急速に進化しており、今後も新しい応用が期待されています。ただし、生成AIの利用にあたっては、倫理的な配慮やデータのプライバシー保護が重要な課題となっています。'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': '回答は生成AIについての基本的な情報を網羅しており、具体例を挙げて説明しています。内容は正確であり、生成AIの応用例や倫理的な課題についても触れているため、ユーザーの質問に対して適切な回答となっています。'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = await compiled.ainvoke(initial_state)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' �́A�����R�}���h�܂��͊O���R�}���h�A\n",
      "����\\�ȃv���O�����܂��̓o�b�` �t�@�C���Ƃ��ĔF������Ă��܂���B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygraphviz\n",
      "  Using cached pygraphviz-1.14.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml): started\n",
      "  Building wheel for pygraphviz (pyproject.toml): finished with status 'error'\n",
      "Failed to build pygraphviz\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [94 lines of output]\n",
      "      C:\\Users\\ktgu1\\AppData\\Local\\Temp\\pip-build-env-lw3xt8zq\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "      \n",
      "              By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        corresp(dist, value, root_dir)\n",
      "      C:\\Users\\ktgu1\\AppData\\Local\\Temp\\pip-build-env-lw3xt8zq\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist._finalize_license_expression()\n",
      "      C:\\Users\\ktgu1\\AppData\\Local\\Temp\\pip-build-env-lw3xt8zq\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      creating build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\pygraphviz\\tests\n",
      "      running egg_info\n",
      "      writing pygraphviz.egg-info\\PKG-INFO\n",
      "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no files found matching '*.swg'\n",
      "      warning: no files found matching '*.png' under directory 'doc'\n",
      "      warning: no files found matching '*.html' under directory 'doc'\n",
      "      warning: no files found matching '*.txt' under directory 'doc'\n",
      "      warning: no files found matching '*.css' under directory 'doc'\n",
      "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "      no previously-included directories found matching 'doc\\build'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-312\\pygraphviz\n",
      "      running build_ext\n",
      "      building 'pygraphviz._graphviz' extension\n",
      "      creating build\\temp.win-amd64-cpython-312\\Release\\pygraphviz\n",
      "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.44.35207\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DSWIG_PYTHON_STRICT_BYTE_CHAR -DGVDLL -Ic:\\Users\\ktgu1\\anaconda3\\include -Ic:\\Users\\ktgu1\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.44.35207\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.26100.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.26100.0\\\\cppwinrt\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-cpython-312\\Release\\pygraphviz\\graphviz_wrap.obj\n",
      "      graphviz_wrap.c\n",
      "      pygraphviz/graphviz_wrap.c(9): warning C4005: 'SWIG_PYTHON_STRICT_BYTE_CHAR': \\x83}\\x83N\\x83\\x8d\\x82\\xaa\\x8dĒ\\xe8\\x8b`\\x82\\xb3\\x82\\xea\\x82܂\\xb5\\x82\\xbd\\x81B\n",
      "      pygraphviz/graphviz_wrap.c(9): note: 'SWIG_PYTHON_STRICT_BYTE_CHAR' \\x82͈ȑO\\x82ɃR\\x83}\\x83\\x93\\x83h \\x83\\x89\\x83C\\x83\\x93\\x82Ő錾\\x82\\xb3\\x82\\xea\\x82Ă\\xa2\\x82܂\\xb7\n",
      "      pygraphviz/graphviz_wrap.c(3023): fatal error C1083: include \\x83t\\x83@\\x83C\\x83\\x8b\\x82\\xf0\\x8aJ\\x82\\xaf\\x82܂\\xb9\\x82\\xf1\\x81B'graphviz/cgraph.h':No such file or directory\n",
      "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.44.35207\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install graphviz libgraphviz-dev pkg-config\n",
    "!pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ktgu1\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph_png.py:137\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m Image(compiled\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_png())\n",
      "File \u001b[1;32mc:\\Users\\ktgu1\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:536\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[1;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[0;32m    525\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PngDrawer(\n\u001b[0;32m    528\u001b[0m     fontname,\n\u001b[0;32m    529\u001b[0m     LabelsDict(\n\u001b[0;32m    530\u001b[0m         nodes\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    531\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_node_labels,\n\u001b[0;32m    532\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m    533\u001b[0m         },\n\u001b[0;32m    534\u001b[0m         edges\u001b[38;5;241m=\u001b[39mlabels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[0;32m    535\u001b[0m     ),\n\u001b[1;32m--> 536\u001b[0m )\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m, output_file_path)\n",
      "File \u001b[1;32mc:\\Users\\ktgu1\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph_png.py:139\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[0;32m    144\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(compiled.get_graph().draw_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
